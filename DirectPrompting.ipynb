{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T15:44:42.804953Z","iopub.execute_input":"2024-10-07T15:44:42.805348Z","iopub.status.idle":"2024-10-07T15:44:42.811641Z","shell.execute_reply.started":"2024-10-07T15:44:42.805313Z","shell.execute_reply":"2024-10-07T15:44:42.810519Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:44:42.813179Z","iopub.execute_input":"2024-10-07T15:44:42.813533Z","iopub.status.idle":"2024-10-07T15:44:43.823200Z","shell.execute_reply.started":"2024-10-07T15:44:42.813482Z","shell.execute_reply":"2024-10-07T15:44:43.822229Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Wed_Nov_22_10:17:15_PST_2023\nCuda compilation tools, release 12.3, V12.3.107\nBuild cuda_12.3.r12.3/compiler.33567101_0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install llama-cpp-python \\\n  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu123","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:44:43.824651Z","iopub.execute_input":"2024-10-07T15:44:43.824954Z","iopub.status.idle":"2024-10-07T15:44:55.305048Z","shell.execute_reply.started":"2024-10-07T15:44:43.824922Z","shell.execute_reply":"2024-10-07T15:44:55.304079Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu123\nRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.3.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_cpp import Llama\nimport tqdm\n\nllm = Llama.from_pretrained(\n    repo_id=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\",\n    filename=\"Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\",\n    n_ctx = 4096\n)\n\n\nquestions = [\n    \"\"\"Here's the idea: \"{}\"\nWhat genre(s) could this story fall into? Answer in 1 sentence.\n\"\"\",\n    \"What kind of message do you want the story to have? Answer in 1 sentence.\",\n    \"Are there any sub-themes you want to incorporate? Answer in 1 sentence.\",\n    \"Summarize the plot of the story for me in a single line.\"\n    \"In what time period does your story take place? Answer in 1 sentence.\",\n    \"What's the primary setting or location? Answer in 1 sentence.\",\n    \"Are there any unique aspects of this world that affect the story? Answer in 1 sentence.\",\n    \"Are there any social, political, or technological elements that are important? Answer in 1 sentence.\",\n    \"Who is your protagonist? What do they want?\",\n    \"What obstacles stand in their way?\",\n    \"Who are the other key characters?\",\n    \"What are the relationships between characters?\",\n    \"What motivates each character's actions?\",\n    \"What flaws or quirks make your characters interesting?\",\n    \"What inciting incident sets the story in motion? Answer in 1 sentence.\",\n    \"What are the key events or turning points?\",\n    \"What is the main conflict (internal, external, or both)?\",\n    \"How will the tension escalate?\",\n    \"What's at stake for the characters?\",\n    \"How might the story end? What changes for the characters?\",\n    \"Which scene or moment will you focus on?\",\n    \"What context can you imply rather than state directly?\",\n    \"Which details are essential to include?\",\n    \"What sensory elements can quickly establish the setting?\",\n    \"\"\"Make me an outline for making a flash fiction story using all of this information. \nThis story will have a maximum word limit of 700-1000 words; so you would only be able to focus on the one scene. Having said that, break this scene up into beats for the outline. \nDo not plan for sudden jumps in time/location between these beats, unless absolutely necessary.\n\nAdd some details about the characters, and the setting of this scene at the end. Use a maximum of 500 words.\n\n\"\"\",\n    \"Write a story of between 700-1000 words using this outline.\"\n]\n\n\n\ndef make_story(idea):\n    qs = list(questions)\n    qs[0] = qs[0].format(idea)\n    \n    messages = [\n        {'role': 'system', 'content': 'Over the next couple of messages, I want you to build up elements for a story (flash fiction) - which you will later use to make an outline. Use a maximum of 5 sentences unless instructed otherwise.'},\n    ]\n\n    \n    for q in tqdm.tqdm(qs):\n        messages.append({'role': 'user', 'content': q})\n        print(messages[-1])\n        output_message = llm.create_chat_completion(messages)['choices'][0]['message']\n        print(output_message)\n        messages.append(output_message)\n\n    return messages, output_message['content']","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:44:55.306797Z","iopub.execute_input":"2024-10-07T15:44:55.307718Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Meta-Llama-3.1-8B-Instruct-Q8_0.gguf:   0%|          | 0.00/8.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83095dca62de4a70910218aeb444865f"}},"metadata":{}}]},{"cell_type":"code","source":"messages, story = make_story('I\\'ve had enough.')\n\nprint(story)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prompt_story_direct(idea):\n    prompt = f\"Write me a story around 700-1000 words based on the idea: '{idea}'\"\n    \n    messages = [{'role':'user', 'content': prompt}]\n    output_message = llm.create_chat_completion(messages)['choices'][0]['message']\n    \n    return output_message, output_message['content']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, story = prompt_story_direct('I\\'ve had enough.')\n\nprint(story)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}