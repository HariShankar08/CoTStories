{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T14:55:54.163735Z","iopub.execute_input":"2024-10-07T14:55:54.164293Z","iopub.status.idle":"2024-10-07T14:55:55.118515Z","shell.execute_reply.started":"2024-10-07T14:55:54.164258Z","shell.execute_reply":"2024-10-07T14:55:55.117576Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:55:55.120789Z","iopub.execute_input":"2024-10-07T14:55:55.121285Z","iopub.status.idle":"2024-10-07T14:55:56.167873Z","shell.execute_reply.started":"2024-10-07T14:55:55.121241Z","shell.execute_reply":"2024-10-07T14:55:56.166770Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Wed_Nov_22_10:17:15_PST_2023\nCuda compilation tools, release 12.3, V12.3.107\nBuild cuda_12.3.r12.3/compiler.33567101_0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install llama-cpp-python \\\n  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu123","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:55:56.169482Z","iopub.execute_input":"2024-10-07T14:55:56.169952Z","iopub.status.idle":"2024-10-07T14:57:52.269100Z","shell.execute_reply.started":"2024-10-07T14:55:56.169912Z","shell.execute_reply":"2024-10-07T14:57:52.268106Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu123\nCollecting llama-cpp-python\n  Downloading llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nCollecting diskcache>=5.6.1 (from llama-cpp-python)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp310-cp310-linux_x86_64.whl size=3511090 sha256=b757714740a39dfcca2be756cc61818a25d0e0b6ce8f43686ebef515ec5d282e\n  Stored in directory: /root/.cache/pip/wheels/f8/b0/a2/f47d952aec7ab061b9e2a345e23a1e1e137beb7891259e3d0c\nSuccessfully built llama-cpp-python\nInstalling collected packages: diskcache, llama-cpp-python\nSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_cpp import Llama\nimport tqdm\n\nllm = Llama.from_pretrained(\n\trepo_id=\"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF\",\n\tfilename=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n    n_ctx=4096,\n)\n\nquestions = [\n    \"\"\"Here's the idea: \"{}\"\nWhat genre(s) could this story fall into? Answer in 1 sentence.\n\"\"\",\n    \"What kind of message do you want the story to have? Answer in 1 sentence.\",\n    \"Are there any sub-themes you want to incorporate? Answer in 1 sentence.\",\n    \"Summarize the plot of the story for me in a single line.\"\n    \"In what time period does your story take place? Answer in 1 sentence.\",\n    \"What's the primary setting or location? Answer in 1 sentence.\",\n    \"Are there any unique aspects of this world that affect the story? Answer in 1 sentence.\",\n    \"Are there any social, political, or technological elements that are important? Answer in 1 sentence.\",\n    \"Who is your protagonist? What do they want?\",\n    \"What obstacles stand in their way?\",\n    \"Who are the other key characters?\",\n    \"What are the relationships between characters?\",\n    \"What motivates each character's actions?\",\n    \"What flaws or quirks make your characters interesting?\",\n    \"What inciting incident sets the story in motion? Answer in 1 sentence.\",\n    \"What are the key events or turning points?\",\n    \"What is the main conflict (internal, external, or both)?\",\n    \"How will the tension escalate?\",\n    \"What's at stake for the characters?\",\n    \"How might the story end? What changes for the characters?\",\n    \"Which scene or moment will you focus on?\",\n    \"What context can you imply rather than state directly?\",\n    \"Which details are essential to include?\",\n    \"What sensory elements can quickly establish the setting?\",\n    \"\"\"Make me an outline for making a flash fiction story using all of this information. \nThis story will have a maximum word limit of 700-1000 words; so you would only be able to focus on the one scene. Having said that, break this scene up into beats for the outline. \nDo not plan for sudden jumps in time/location between these beats, unless absolutely necessary.\n\nAdd some details about the characters, and the setting of this scene at the end. Use a maximum of 500 words.\n\n\"\"\",\n    \"Write a story of between 700-1000 words using this outline.\"\n]\n\n\n\ndef make_story(idea):\n    qs = list(questions)\n    qs[0] = qs[0].format(idea)\n    \n    messages = [\n        {'role': 'system', 'content': 'Over the next couple of messages, I want you to build up elements for a story (flash fiction) - which you will later use to make an outline. Use a maximum of 5 sentences unless instructed otherwise.'},\n    ]\n\n    \n    for q in tqdm.tqdm(qs):\n        messages.append({'role': 'user', 'content': q})\n        print(messages[-1])\n        output_message = llm.create_chat_completion(messages)['choices'][0]['message']\n        print(output_message)\n        messages.append(output_message)\n\n    return messages, output_message['content']","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:57:52.271258Z","iopub.execute_input":"2024-10-07T14:57:52.271607Z","iopub.status.idle":"2024-10-07T14:58:09.184539Z","shell.execute_reply.started":"2024-10-07T14:57:52.271572Z","shell.execute_reply":"2024-10-07T14:58:09.183507Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Meta-Llama-3-8B-Instruct.Q4_0.gguf:   0%|          | 0.00/4.66G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b2f201b10eb4027bfa7c4e592af4deb"}},"metadata":{}},{"name":"stderr","text":"llama_model_loader: loaded meta data with 27 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--QuantFactory--Meta-Llama-3-8B-Instruct-GGUF/snapshots/86e0c07efa3f1b6f06ea13e31b1e930dce865ae4/./Meta-Llama-3-8B-Instruct.Q4_0.gguf (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Models\nllama_model_loader: - kv   3:                         general.size_label str              = 8.0B\nllama_model_loader: - kv   4:                            general.license str              = llama3\nllama_model_loader: - kv   5:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\nllama_model_loader: - kv   6:                          general.languages arr[str,1]       = [\"en\"]\nllama_model_loader: - kv   7:                          llama.block_count u32              = 32\nllama_model_loader: - kv   8:                       llama.context_length u32              = 8192\nllama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\nllama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  15:                          general.file_type u32              = 2\nllama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\nllama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\nllama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\nllama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\nllama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\nllama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\nllama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\nllama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\nllama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\nllama_model_loader: - kv  26:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_0:  225 tensors\nllama_model_loader: - type q6_K:    1 tensors\nllm_load_vocab: special tokens cache size = 256\nllm_load_vocab: token to piece cache size = 0.8000 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = BPE\nllm_load_print_meta: n_vocab          = 128256\nllm_load_print_meta: n_merges         = 280147\nllm_load_print_meta: vocab_only       = 0\nllm_load_print_meta: n_ctx_train      = 8192\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_swa            = 0\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 500000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 8192\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: ssm_dt_b_c_rms   = 0\nllm_load_print_meta: model type       = 8B\nllm_load_print_meta: model ftype      = Q4_0\nllm_load_print_meta: model params     = 8.03 B\nllm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \nllm_load_print_meta: general.name     = Models\nllm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\nllm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\nllm_load_print_meta: LF token         = 128 'Ä'\nllm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\nllm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\nllm_load_print_meta: max token length = 256\nllm_load_tensors: ggml ctx size =    0.14 MiB\nllm_load_tensors:        CPU buffer size =  4437.80 MiB\n.......................................................................................\nllama_new_context_with_model: n_ctx      = 4096\nllama_new_context_with_model: n_batch    = 512\nllama_new_context_with_model: n_ubatch   = 512\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 500000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\nllama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\nllama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\nllama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\nllama_new_context_with_model: graph nodes  = 1030\nllama_new_context_with_model: graph splits = 1\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \nModel metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Models', 'general.type': 'model', 'general.size_label': '8.0B', 'general.license': 'llama3', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\nAvailable chat formats from metadata: chat_template.default\nGuessed chat format: llama-3\n","output_type":"stream"}]},{"cell_type":"code","source":"messages, story = make_story('I\\'ve had enough.')\n\nprint(story)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T11:26:00.274842Z","iopub.execute_input":"2024-10-07T11:26:00.275155Z","iopub.status.idle":"2024-10-07T11:45:31.708138Z","shell.execute_reply.started":"2024-10-07T11:26:00.275121Z","shell.execute_reply":"2024-10-07T11:45:31.706951Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"  0%|          | 0/25 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"{'role': 'user', 'content': 'Here\\'s the idea: \"I\\'ve had enough.\"\\nWhat genre(s) could this story fall into? Answer in 1 sentence.\\n'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   25621.55 ms /   122 tokens\n  4%|▍         | 1/25 [00:25<10:15, 25.63s/it]Llama.generate: 122 prefix-match hit, remaining 28 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'This phrase could fall into the genres of Science Fiction, Mystery, or Psychological Thriller, as it suggests a protagonist who has reached a breaking point and is prepared to take drastic action.'}\n{'role': 'user', 'content': 'What kind of message do you want the story to have? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    28 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   17428.06 ms /    63 tokens\n  8%|▊         | 2/25 [00:43<07:58, 20.81s/it]Llama.generate: 185 prefix-match hit, remaining 27 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"I want the story to have a message about the importance of standing up for oneself and taking control of one's life when faced with injustice, inequality, or personal mistreatment.\"}\n{'role': 'user', 'content': 'Are there any sub-themes you want to incorporate? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    27 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   17543.39 ms /    62 tokens\n 12%|█▏        | 3/25 [01:00<07:05, 19.32s/it]Llama.generate: 247 prefix-match hit, remaining 40 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"I'd like to incorporate sub-themes of empowerment, resilience, and the struggle for identity, as the protagonist navigates their moment of realization and decides what actions to take.\"}\n{'role': 'user', 'content': 'Summarize the plot of the story for me in a single line.In what time period does your story take place? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    40 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   20509.33 ms /    79 tokens\n 16%|█▌        | 4/25 [01:21<06:55, 19.79s/it]Llama.generate: 326 prefix-match hit, remaining 24 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'The story follows a protagonist who has reached a breaking point and decides to take a stand against the forces that have been holding them back, set in the present day with a focus on contemporary issues.'}\n{'role': 'user', 'content': \"What's the primary setting or location? Answer in 1 sentence.\"}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    24 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   16450.12 ms /    58 tokens\n 20%|██        | 5/25 [01:37<06:11, 18.59s/it]Llama.generate: 384 prefix-match hit, remaining 29 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'The primary setting is a small, isolated town or community, where the protagonist feels trapped and suffocated by the societal norms and expectations that they are trying to challenge.'}\n{'role': 'user', 'content': 'Are there any unique aspects of this world that affect the story? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   15570.75 ms /    58 tokens\n 24%|██▍       | 6/25 [01:53<05:33, 17.56s/it]Llama.generate: 442 prefix-match hit, remaining 30 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'The town is plagued by a mysterious phenomenon where technology and electricity are unreliable, adding to the sense of isolation and disconnection that the protagonist feels.'}\n{'role': 'user', 'content': 'Are there any social, political, or technological elements that are important? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   16636.08 ms /    62 tokens\n 28%|██▊       | 7/25 [02:09<05:10, 17.26s/it]Llama.generate: 504 prefix-match hit, remaining 20 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The story features a backdrop of systemic inequality and social unrest, with the protagonist's personal struggles reflecting and responding to the larger issues of systemic oppression and marginalized communities.\"}\n{'role': 'user', 'content': 'Who is your protagonist? What do they want?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    20 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    52 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   23721.63 ms /    72 tokens\n 32%|███▏      | 8/25 [02:33<05:28, 19.32s/it]Llama.generate: 576 prefix-match hit, remaining 17 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'The protagonist is a young adult, a member of a marginalized community who has been subjected to discrimination, harassment, and marginalization, and who wants to break free from the constraints of their oppressive environment and assert their individuality, autonomy, and sense of self.'}\n{'role': 'user', 'content': 'What obstacles stand in their way?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    17 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   20573.75 ms /    62 tokens\n 36%|███▌      | 9/25 [02:54<05:15, 19.71s/it]Llama.generate: 638 prefix-match hit, remaining 17 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The protagonist faces several obstacles, including internalized self-doubt, societal expectations, and external forces of oppression, which are perpetuated by the town's authorities, local business owners, and even their own family and friends.\"}\n{'role': 'user', 'content': 'Who are the other key characters?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    17 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    58 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   25478.19 ms /    75 tokens\n 40%|████      | 10/25 [03:19<05:22, 21.50s/it]Llama.generate: 713 prefix-match hit, remaining 17 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The other key characters are the protagonist's closest friend and confidant, who is torn between loyalty to the protagonist and the fear of repercussions from the town's authorities, and the town's charismatic but ruthless leader, who uses manipulation and coercion to maintain control over the town and its residents.\"}\n{'role': 'user', 'content': 'What are the relationships between characters?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    17 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    61 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   27176.85 ms /    78 tokens\n 44%|████▍     | 11/25 [03:46<05:25, 23.24s/it]Llama.generate: 791 prefix-match hit, remaining 18 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The protagonist and their friend have a deep bond of trust and shared experience, while the protagonist and the town's leader have a history of conflict and resentment, with the leader viewing the protagonist as a threat to their authority and the protagonist seeing the leader as a symbol of everything that is wrong with their town.\"}\n{'role': 'user', 'content': \"What motivates each character's actions?\"}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    77 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   33514.37 ms /    95 tokens\n 48%|████▊     | 12/25 [04:20<05:42, 26.37s/it]Llama.generate: 886 prefix-match hit, remaining 20 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The protagonist is motivated by a desire for freedom, autonomy, and self-expression, as well as a sense of justice and a need to protect themselves and others from the oppressive forces that surround them. The town's leader is motivated by a desire for power, control, and self-preservation, and is willing to use manipulation, coercion, and intimidation to maintain their grip on the town.\"}\n{'role': 'user', 'content': 'What flaws or quirks make your characters interesting?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    20 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    54 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   24840.43 ms /    74 tokens\n 52%|█████▏    | 13/25 [04:45<05:10, 25.91s/it]Llama.generate: 960 prefix-match hit, remaining 26 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The protagonist has a tendency to self-doubt and second-guess themselves, which can hold them back from taking bold action, while the town's leader has a charismatic and charming exterior that belies their ruthless and calculating nature, making them a complex and intriguing character.\"}\n{'role': 'user', 'content': 'What inciting incident sets the story in motion? Answer in 1 sentence.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    26 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   22083.27 ms /    71 tokens\n 56%|█████▌    | 14/25 [05:07<04:32, 24.75s/it]Llama.generate: 1031 prefix-match hit, remaining 19 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The inciting incident is the protagonist's best friend and confidant being taken away by the town's authorities, sparking the protagonist's determination to take a stand and fight against the oppressive forces that have been holding them back.\"}\n{'role': 'user', 'content': 'What are the key events or turning points?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    77 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   34205.81 ms /    96 tokens\n 60%|██████    | 15/25 [05:41<04:36, 27.60s/it]Llama.generate: 1127 prefix-match hit, remaining 23 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The key events or turning points include the protagonist's initial acts of defiance, which lead to escalating tension and conflict with the town's leader and authorities; a dramatic confrontation with the leader that sets off a chain reaction of consequences; and a climactic moment where the protagonist must make a choice between standing by their friend and risking everything, or backing down and sacrificing their own values and integrity.\"}\n{'role': 'user', 'content': 'What is the main conflict (internal, external, or both)?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    23 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    55 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   26241.31 ms /    78 tokens\n 64%|██████▍   | 16/25 [06:07<04:04, 27.20s/it]Llama.generate: 1205 prefix-match hit, remaining 16 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': 'The main conflict is an external conflict between the protagonist and the oppressive forces of the town, but it is also an internal conflict as the protagonist grapples with their own self-doubt, fear, and uncertainty about how to take a stand and challenge the status quo.'}\n{'role': 'user', 'content': 'How will the tension escalate?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    54 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   24387.56 ms /    70 tokens\n 68%|██████▊   | 17/25 [06:32<03:30, 26.35s/it]Llama.generate: 1275 prefix-match hit, remaining 18 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The tension will escalate as the protagonist's defiance and resistance to the town's authorities lead to increased surveillance, intimidation, and repression, causing the protagonist to face escalating consequences and risks, including personal and physical harm, and ultimately a climactic showdown with the town's leader.\"}\n{'role': 'user', 'content': \"What's at stake for the characters?\"}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    90 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   39878.56 ms /   108 tokens\n 72%|███████▏  | 18/25 [07:11<03:32, 30.42s/it]Llama.generate: 1383 prefix-match hit, remaining 22 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"What's at stake for the protagonist is their sense of self, their freedom, and their very identity, as they risk being silenced, imprisoned, or even forced to flee in order to assert their autonomy and challenge the oppressive forces that have held them back. For the town's leader, what's at stake is their grip on power, their reputation, and their legacy, as they risk being overthrown or humiliated if the protagonist's resistance succeeds.\"}\n{'role': 'user', 'content': 'How might the story end? What changes for the characters?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    22 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    70 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   32323.28 ms /    92 tokens\n 76%|███████▌  | 19/25 [07:44<03:05, 30.99s/it]Llama.generate: 1475 prefix-match hit, remaining 19 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"The story could end with the protagonist emerging victorious, having successfully challenged the town's leader and brought about change, but with scars and a newfound sense of responsibility to continue fighting for justice and equality. Alternatively, the story could end with the protagonist making a difficult choice to flee or compromise, leaving behind a legacy of resistance and a hope for future change.\"}\n{'role': 'user', 'content': 'Which scene or moment will you focus on?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   20720.52 ms /    63 tokens\n 80%|████████  | 20/25 [08:05<02:19, 27.91s/it]Llama.generate: 1538 prefix-match hit, remaining 20 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"I'll focus on the moment when the protagonist stands up to the town's leader and makes a bold declaration of resistance, marking a turning point in the story and setting the stage for the escalating tension and conflict that follows.\"}\n{'role': 'user', 'content': 'What context can you imply rather than state directly?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    20 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   21129.72 ms /    64 tokens\n 84%|████████▍ | 21/25 [08:26<01:43, 25.88s/it]Llama.generate: 1602 prefix-match hit, remaining 17 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"I can imply that the town has a dark history of oppression and exploitation, and that the protagonist's family and community have been affected by this history, without explicitly stating it, through subtle hints and suggestions throughout the story.\"}\n{'role': 'user', 'content': 'Which details are essential to include?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    17 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    56 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   25948.04 ms /    73 tokens\n 88%|████████▊ | 22/25 [08:52<01:17, 25.90s/it]Llama.generate: 1675 prefix-match hit, remaining 19 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"Essential details to include are the protagonist's emotional struggles and inner turmoil, the town's oppressive atmosphere and the protagonist's sense of isolation and disconnection, and the protagonist's relationship with their friend and the leader, as these details will help to create a rich and nuanced story.\"}\n{'role': 'user', 'content': 'What sensory elements can quickly establish the setting?'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /    68 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =   31206.99 ms /    87 tokens\n 92%|█████████▏| 23/25 [09:23<00:54, 27.50s/it]Llama.generate: 1762 prefix-match hit, remaining 113 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"To quickly establish the setting, I can use sensory elements such as the protagonist's sense of dusty, stale air filling their lungs, the faint smell of decay and neglect wafting from the abandoned buildings, and the sound of distant, muffled sirens echoing through the streets, evoking a sense of unease and foreboding.\"}\n{'role': 'user', 'content': 'Make me an outline for making a flash fiction story using all of this information. \\nThis story will have a maximum word limit of 700-1000 words; so you would only be able to focus on the one scene. Having said that, break this scene up into beats for the outline. \\nDo not plan for sudden jumps in time/location between these beats, unless absolutely necessary.\\n\\nAdd some details about the characters, and the setting of this scene at the end. Use a maximum of 500 words.\\n\\n'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /   113 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /   621 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =  280645.59 ms /   734 tokens\n 96%|█████████▌| 24/25 [14:04<01:43, 103.46s/it]Llama.generate: 2496 prefix-match hit, remaining 25 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': '**Flash Fiction Outline: \"I\\'ve Had Enough\"**\\n\\n**Scene:** The protagonist, JESSICA, stands outside the town\\'s central square, where the oppressive leader, MAYOR HARRISON, is giving a speech to the townspeople.\\n\\n**Beat 1: Setup**\\n\\n* Introduce Jessica, a young adult who\\'s been struggling to make a living in this small, isolated town.\\n* Show her walking into the central square, where she\\'s surrounded by the town\\'s residents, all staring at Mayor Harrison.\\n* Establish the oppressive atmosphere, with hints at the town\\'s dark history and the protagonist\\'s sense of isolation and disconnection.\\n\\n**Beat 2: The Inciting Incident**\\n\\n* Mayor Harrison begins his speech, boasting about the town\\'s \"progress\" and \"prosperity.\"\\n* Jessica, fed up with the mayor\\'s empty promises and the town\\'s stagnant state, decides to take a stand.\\n* She pushes her way to the front, her eyes locked on the mayor, and begins to shout her dissent.\\n\\n**Beat 3: The Confrontation**\\n\\n* Mayor Harrison, taken aback by Jessica\\'s outburst, tries to shut her down with his charm and authority.\\n* Jessica refuses to back down, citing the town\\'s history of oppression and the mayor\\'s role in perpetuating it.\\n* The crowd begins to take sides, with some residents supporting the mayor and others backing Jessica.\\n\\n**Beat 4: The Turning Point**\\n\\n* Jessica\\'s boldness sparks a chain reaction of reactions, with some residents beginning to whisper among themselves and others looking on with a mixture of fear and curiosity.\\n* The mayor, realizing his grip on the town is slipping, grows more aggressive and menacing.\\n* Jessica, sensing the danger, takes a step forward, her eyes flashing with determination.\\n\\n**Beat 5: The Climax**\\n\\n* Jessica and the mayor engage in a heated confrontation, with the town\\'s residents watching in rapt attention.\\n* The air is electric with tension as the two adversaries face off, each refusing to back down.\\n\\n**Beat 6: The Resolution**\\n\\n* The standoff ends abruptly, with the mayor storming off, leaving Jessica standing tall, her defiance broadcast to the entire town.\\n* The crowd begins to disperse, some residents whispering among themselves, others looking on with a mixture of awe and fear.\\n\\n**Character and Setting:**\\n\\n* Jessica: A young adult, 20-25 years old, with a fiery spirit and a desire for change. She\\'s been struggling to make a living in the town and has grown tired of the mayor\\'s empty promises.\\n* Mayor Harrison: A charismatic, ruthless leader who\\'s used his charm and authority to maintain control over the town. He\\'s in his 40s, with a reputation for being unscrupulous.\\n* The Town: A small, isolated town with a dark history of oppression and exploitation. The town is run-down, with abandoned buildings and a sense of decay and neglect. The air is thick with tension and the sounds of distant sirens echo through the streets.'}\n{'role': 'user', 'content': 'Write a story of between 700-1000 words using this outline.'}\n","output_type":"stream"},{"name":"stderr","text":"llama_perf_context_print:        load time =   10588.50 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    25 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /   733 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =  327403.78 ms /   758 tokens\n100%|██████████| 25/25 [19:31<00:00, 46.86s/it] ","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': '\"I\\'ve Had Enough\"\\n\\nThe sun beat down on the town\\'s central square, casting a harsh light on the dusty, worn-down buildings that lined the streets. The air was heavy with the scent of decay and neglect, a constant reminder of the town\\'s stagnant state. Jessica, a young adult with a fiery spirit, walked into the square, her eyes scanning the crowd of townspeople gathered to hear Mayor Harrison\\'s speech.\\n\\nJessica had grown tired of the mayor\\'s empty promises and the town\\'s lack of progress. She was sick of hearing the same tired phrases, day in and day out, as the mayor boasted about the town\\'s \"prosperity\" and \"growth.\" But today, something was different. Today, Jessica had had enough.\\n\\nAs she pushed her way to the front of the crowd, Mayor Harrison\\'s voice boomed out, touting the town\\'s achievements and declaring that this was the best year yet. But Jessica wasn\\'t buying it. She had seen the same promises made and broken time and time again. And she knew that the town was still trapped in a cycle of oppression and exploitation.\\n\\nThe mayor, oblivious to Jessica\\'s growing frustration, continued to speak, his words dripping with condescension and control. But Jessica was having none of it. She took a step forward, her eyes flashing with determination, and began to shout her dissent.\\n\\n\"Enough is enough!\" she cried, her voice carrying across the square. \"We deserve better than empty promises and broken dreams! We deserve a life of purpose and fulfillment, not just a life of stagnation and despair!\"\\n\\nThe crowd began to stir, some residents looking on with a mixture of fear and curiosity. But others, emboldened by Jessica\\'s courage, began to whisper among themselves. The mayor, taken aback by Jessica\\'s outburst, tried to shut her down with his charm and authority.\\n\\n\"Jessica, dear, you\\'re just a passionate young woman,\" he said, his voice dripping with condescension. \"You don\\'t understand the complexities of governing a town like ours. We have to make tough decisions to keep our economy growing and our people safe.\"\\n\\nBut Jessica was not to be swayed. She refused to back down, citing the town\\'s history of oppression and exploitation, and the mayor\\'s role in perpetuating it. The crowd began to take sides, with some residents supporting the mayor and others backing Jessica.\\n\\nThe air was electric with tension as the two adversaries faced off, each refusing to back down. The mayor\\'s face grew red with anger, but Jessica stood tall, her eyes flashing with defiance.\\n\\n\"I won\\'t be silenced,\" she cried, her voice carrying across the square. \"I won\\'t be bullied or intimidated. I\\'ll keep fighting for what\\'s right, even if it means going up against you and your cronies!\"\\n\\nThe standoff ended abruptly, with the mayor storming off, leaving Jessica standing tall, her defiance broadcast to the entire town. The crowd began to disperse, some residents whispering among themselves, others looking on with a mixture of awe and fear.\\n\\nAs Jessica turned to leave, she saw the mayor\\'s face, twisted with anger and hatred. But she refused to back down. She knew that she had taken the first step towards change, and that nothing would ever be the same again.\\n\\nFrom that day on, the town was never the same. The mayor\\'s grip on power began to slip, and the townspeople began to stir. They started to question the status quo, to demand change and accountability. And Jessica, the young woman who had had enough, was at the forefront of it all.'}\n\"I've Had Enough\"\n\nThe sun beat down on the town's central square, casting a harsh light on the dusty, worn-down buildings that lined the streets. The air was heavy with the scent of decay and neglect, a constant reminder of the town's stagnant state. Jessica, a young adult with a fiery spirit, walked into the square, her eyes scanning the crowd of townspeople gathered to hear Mayor Harrison's speech.\n\nJessica had grown tired of the mayor's empty promises and the town's lack of progress. She was sick of hearing the same tired phrases, day in and day out, as the mayor boasted about the town's \"prosperity\" and \"growth.\" But today, something was different. Today, Jessica had had enough.\n\nAs she pushed her way to the front of the crowd, Mayor Harrison's voice boomed out, touting the town's achievements and declaring that this was the best year yet. But Jessica wasn't buying it. She had seen the same promises made and broken time and time again. And she knew that the town was still trapped in a cycle of oppression and exploitation.\n\nThe mayor, oblivious to Jessica's growing frustration, continued to speak, his words dripping with condescension and control. But Jessica was having none of it. She took a step forward, her eyes flashing with determination, and began to shout her dissent.\n\n\"Enough is enough!\" she cried, her voice carrying across the square. \"We deserve better than empty promises and broken dreams! We deserve a life of purpose and fulfillment, not just a life of stagnation and despair!\"\n\nThe crowd began to stir, some residents looking on with a mixture of fear and curiosity. But others, emboldened by Jessica's courage, began to whisper among themselves. The mayor, taken aback by Jessica's outburst, tried to shut her down with his charm and authority.\n\n\"Jessica, dear, you're just a passionate young woman,\" he said, his voice dripping with condescension. \"You don't understand the complexities of governing a town like ours. We have to make tough decisions to keep our economy growing and our people safe.\"\n\nBut Jessica was not to be swayed. She refused to back down, citing the town's history of oppression and exploitation, and the mayor's role in perpetuating it. The crowd began to take sides, with some residents supporting the mayor and others backing Jessica.\n\nThe air was electric with tension as the two adversaries faced off, each refusing to back down. The mayor's face grew red with anger, but Jessica stood tall, her eyes flashing with defiance.\n\n\"I won't be silenced,\" she cried, her voice carrying across the square. \"I won't be bullied or intimidated. I'll keep fighting for what's right, even if it means going up against you and your cronies!\"\n\nThe standoff ended abruptly, with the mayor storming off, leaving Jessica standing tall, her defiance broadcast to the entire town. The crowd began to disperse, some residents whispering among themselves, others looking on with a mixture of awe and fear.\n\nAs Jessica turned to leave, she saw the mayor's face, twisted with anger and hatred. But she refused to back down. She knew that she had taken the first step towards change, and that nothing would ever be the same again.\n\nFrom that day on, the town was never the same. The mayor's grip on power began to slip, and the townspeople began to stir. They started to question the status quo, to demand change and accountability. And Jessica, the young woman who had had enough, was at the forefront of it all.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def prompt_story_direct(idea):\n    prompt = f\"Write me a story around 700-1000 words based on the idea: '{idea}'\"\n    \n    messages = [{'role':'user', 'content': prompt}]\n    output_message = llm.create_chat_completion(messages)['choices'][0]['message']\n    \n    return output_message, output_message['content']","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:00:54.338313Z","iopub.execute_input":"2024-10-07T15:00:54.339264Z","iopub.status.idle":"2024-10-07T15:00:54.344319Z","shell.execute_reply.started":"2024-10-07T15:00:54.339214Z","shell.execute_reply":"2024-10-07T15:00:54.343373Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"_, story = prompt_story_direct('I\\'ve had enough.')\n\nprint(story)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:00:54.673206Z","iopub.execute_input":"2024-10-07T15:00:54.674163Z","iopub.status.idle":"2024-10-07T15:06:53.357148Z","shell.execute_reply.started":"2024-10-07T15:00:54.674120Z","shell.execute_reply":"2024-10-07T15:06:53.356134Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"llama_perf_context_print:        load time =    4420.56 ms\nllama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:        eval time =       0.00 ms /   852 runs   (    0.00 ms per token,      inf tokens per second)\nllama_perf_context_print:       total time =  358674.21 ms /   884 tokens\n","output_type":"stream"},{"name":"stdout","text":"Emily woke up to the sound of her alarm blaring in her ear. She groggily reached over to turn it off, her mind still foggy from the long night she had ahead of her. She worked the night shift at the hospital, and it was a never-ending cycle of exhaustion and fatigue. She rubbed her tired eyes, wondering how she was going to make it through another day.\n\nAs she got dressed and headed out the door, Emily couldn't help but think about how her life had become so monotonous. She was 28 years old, and it felt like she was stuck in a rut. Her job was unfulfilling, her social life was non-existent, and her relationship with her boyfriend was strained. She felt like she was just going through the motions every day, without any sense of purpose or fulfillment.\n\nWhen she arrived at the hospital, Emily was greeted by the usual chaos and commotion. She clocked in, and began her rounds, checking in on her patients and taking their vitals. She was a skilled and dedicated nurse, but even her passion and dedication couldn't mask the monotony of her job. She felt like she was just a cog in a machine, a replaceable part that could be swapped out at any moment.\n\nAs the day wore on, Emily's frustration grew. She felt like she was being pulled in a million different directions, with no time to take a breath. The patients were demanding, the doctors were always on her case, and the administrators were breathing down her neck. She was constantly running, never stopping to catch her breath, never taking the time to think about what she really wanted.\n\nAt the end of her shift, Emily trudged out of the hospital, feeling like she'd been run over by a truck. She walked home, lost in thought, wondering how she had let things get so bad. She used to be a happy, carefree person, with a sense of purpose and direction. Now, she just felt like a shell of her former self, stuck in a rut that seemed impossible to escape.\n\nAs she walked into her apartment, Emily felt like she was finally going to break down and cry. But something inside of her snapped. She realized that she couldn't keep going on like this, trapped in a life that wasn't hers. She couldn't keep pretending that everything was okay, when everything was anything but.\n\nEmily took a deep breath, and made a decision. She was going to take control of her life, and make some changes. She was going to start saying \"no\" to things that drained her energy, and \"yes\" to things that brought her joy. She was going to start taking care of herself, and prioritize her own happiness.\n\nShe started by quitting her job at the hospital. It was a scary prospect, but she knew it was the right thing to do. She began by looking for a new job that aligned with her values and passions. She started taking classes and workshops to learn new skills, and to meet new people.\n\nAs Emily started to make these changes, she began to feel like herself again. She started to feel like she was living the life she truly wanted, not just going through the motions. She started to feel like she had control over her life, and that anything was possible.\n\nIt wasn't easy, of course. There were setbacks and challenges along the way. But Emily persevered, knowing that she was making the right decision for herself. She started to feel like she was waking up to a new life, one that was full of purpose and excitement.\n\nEmily realized that she had been living someone else's dream, not her own. She had been going through the motions, trying to make everyone else happy, instead of focusing on what truly brought her joy. She had been living a life that wasn't hers, and it was time for her to take control and start living the life she truly wanted.\n\nAs Emily looked out at the world around her, she felt a sense of hope and excitement. She knew that she had the power to create the life she wanted, and that anything was possible. She had finally had enough, and it was time for her to start living.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}